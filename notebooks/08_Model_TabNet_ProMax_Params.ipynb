{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- Sklearn ---\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, brier_score_loss, log_loss, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# --- TabNet & PyTorch ---\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Utility functions + Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (can be imported from a utils file or redefined) ---\n",
    "def calculate_ks(y_true, y_prob):\n",
    "    \"\"\"Calculates the Kolmogorov-Smirnov (KS) statistic.\"\"\"\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "    df = df.sort_values(by='y_prob', ascending=False)\n",
    "    # Ensure y_true sums are not zero before division\n",
    "    sum_true = df['y_true'].sum()\n",
    "    sum_false = len(df) - sum_true\n",
    "    if sum_true == 0 or sum_false == 0:\n",
    "        return 0.0 # KS is 0 if one class is missing\n",
    "    df['cumulative_true'] = df['y_true'].cumsum() / sum_true\n",
    "    df['cumulative_false'] = (1 - df['y_true']).cumsum() / sum_false\n",
    "    ks = max(abs(df['cumulative_true'] - df['cumulative_false']))\n",
    "    return ks\n",
    "\n",
    "def find_optimal_threshold_j_statistic(y_true, y_prob_oof):\n",
    "    \"\"\"Finds the optimal threshold maximizing Youden's J statistic (Sensitivity + Specificity - 1).\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob_oof)\n",
    "     # Handle cases where thresholds might not be strictly decreasing\n",
    "    valid_indices = np.where(np.isfinite(thresholds))[0]\n",
    "    if len(valid_indices) == 0:\n",
    "        print(\"Warning: No valid thresholds found for J-statistic calculation.\")\n",
    "        return 0.5 # Default fallback\n",
    "    fpr, tpr, thresholds = fpr[valid_indices], tpr[valid_indices], thresholds[valid_indices]\n",
    "\n",
    "    if len(thresholds) == 0:\n",
    "         print(\"Warning: Threshold array is empty after filtering.\")\n",
    "         return 0.5\n",
    "\n",
    "    j_statistic = tpr - fpr\n",
    "    optimal_idx = np.argmax(j_statistic)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    # Ensure threshold is within [0, 1] bounds if necessary due to floating point issues\n",
    "    optimal_threshold = max(0.0, min(1.0, optimal_threshold))\n",
    "    print(f\"Optimal threshold based on Youden's J-Statistic (OOF): {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def evaluate_model(y_true, y_pred_proba, y_pred_binary, model_name=\"Model\"):\n",
    "    \"\"\"Calculates and prints standard classification metrics.\"\"\"\n",
    "    # Add epsilon to probabilities for log_loss if necessary\n",
    "    eps = 1e-15\n",
    "    y_pred_proba = np.clip(y_pred_proba, eps, 1 - eps)\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
    "    gini = 2 * auc_roc - 1\n",
    "    ks = calculate_ks(y_true, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "    brier = brier_score_loss(y_true, y_pred_proba)\n",
    "    logloss = log_loss(y_true, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "    print(f\"\\n--- Evaluation Metrics for {model_name} ---\")\n",
    "    print(f\"AUC ROC:        {auc_roc:.4f}\")\n",
    "    print(f\"Gini Coefficient: {gini:.4f}\")\n",
    "    print(f\"KS Statistic:   {ks:.4f}\")\n",
    "    print(f\"Accuracy:       {accuracy:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall (TPR):   {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"Brier Score:    {brier:.4f}\")\n",
    "    print(f\"Log Loss:       {logloss:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'AUC': auc_roc, 'Gini': gini, 'KS': ks, 'Accuracy': accuracy,\n",
    "        'Precision': precision, 'Recall': recall, 'F1': f1,\n",
    "        'Brier': brier, 'LogLoss': logloss\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def plot_roc_curve(y_true, y_prob, model_name):\n",
    "    \"\"\"Plots the ROC curve.\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_roc = roc_auc_score(y_true, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_roc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} - ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Save the plot\n",
    "    plot_filename = f\"roc_curve_{model_name.replace(' ', '_')}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"ROC curve saved to {plot_filename}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "DATA_PATH = '../data/processed/'\n",
    "MODEL_OUTPUT_PATH = './tabnet_outputs/' # Directory to save model/results\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'TARGET'\n",
    "ID_COL = 'SK_ID_CURR'\n",
    "\n",
    "# TabNet Specific Config\n",
    "TABNET_PARAMS = dict(\n",
    "    # Network architecture\n",
    "    n_d=186,             \n",
    "    n_a=186,              \n",
    "    n_steps=19,          \n",
    "    n_independent=11,    \n",
    "    n_shared=11,     \n",
    "    \n",
    "    # Regularization\n",
    "    gamma=1.8,         \n",
    "    lambda_sparse=1e-4, \n",
    "    \n",
    "    # Optimizer settings\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler_params=dict(\n",
    "        mode=\"min\", \n",
    "        patience=50,    \n",
    "        min_lr=1e-4, \n",
    "        factor=0.5\n",
    "    ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \n",
    "    mask_type='sparsemax',\n",
    "    verbose=1,\n",
    "    seed=42 \n",
    ")\n",
    "\n",
    "# Training Config\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "BATCH_SIZE = 4096\n",
    "VIRTUAL_BATCH_SIZE = 1024\n",
    "\n",
    "# --- Check for GPU ---\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "print(\"Loading preprocessed data...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(DATA_PATH + 'train_final.csv')\n",
    "    test_df = pd.read_csv(DATA_PATH + 'test_final.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure 'train_final.csv' and 'test_final.csv' are in {DATA_PATH}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data ---\n",
    "y_train = train_df[TARGET].values # Use .values for numpy arrays\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "# Drop Target and potentially ID\n",
    "if ID_COL in train_df.columns:\n",
    "    X_train = train_df.drop(columns=[TARGET, ID_COL])\n",
    "    X_test = test_df.drop(columns=[TARGET, ID_COL])\n",
    "else:\n",
    "    X_train = train_df.drop(columns=[TARGET])\n",
    "    X_test = test_df.drop(columns=[TARGET])\n",
    "\n",
    "# Align columns just in case\n",
    "common_cols = list(X_train.columns.intersection(X_test.columns))\n",
    "X_train = X_train[common_cols]\n",
    "X_test = X_test[common_cols]\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Low Variance Feature Selection...\n",
      "Original number of features: 773\n",
      "Number of features after variance thresholding: 542\n",
      "Updated X_train shape: (246005, 542)\n",
      "Updated X_test shape: (61502, 542)\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Selection: Low Variance Filter ---\n",
    "print(\"\\nApplying Low Variance Feature Selection...\")\n",
    "var_selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Fit on training data only\n",
    "var_selector.fit(X_train)\n",
    "\n",
    "# Get the boolean mask of selected features\n",
    "feature_mask = var_selector.get_support()\n",
    "original_feature_names = X_train.columns.tolist() # Get original names before transformation\n",
    "selected_feature_names = [name for name, selected in zip(original_feature_names, feature_mask) if selected]\n",
    "\n",
    "print(f\"Original number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features after variance thresholding: {len(selected_feature_names)}\")\n",
    "\n",
    "# Transform both X_train and X_test\n",
    "X_train_np_selected = var_selector.transform(X_train)\n",
    "X_test_np_selected = var_selector.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame with selected column names\n",
    "X_train = pd.DataFrame(X_train_np_selected, columns=selected_feature_names, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_np_selected, columns=selected_feature_names, index=X_test.index)\n",
    "\n",
    "# Update the global feature_names list\n",
    "feature_names = selected_feature_names\n",
    "\n",
    "print(f\"Updated X_train shape: {X_train.shape}\")\n",
    "print(f\"Updated X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\n",
      "Prepared X_train shape: (246005, 542)\n",
      "Prepared X_test shape: (61502, 542)\n"
     ]
    }
   ],
   "source": [
    "# --- LIMITATION: Treat all features as numerical ---\n",
    "# Ideally, identify original categorical features and pass their indices to TabNet.\n",
    "# Since we are using pre-encoded data, we treat all as numerical.\n",
    "print(\"WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\")\n",
    "categorical_indices = [] # No categorical indices provided\n",
    "categorical_dims = [] # No specific dimensions needed if indices are empty\n",
    "\n",
    "# Handle infinite values and NaNs\n",
    "# Replace inf with NaN, then fill NaN with median of each column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(X_train.median())\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(X_train.median()) # Use train median for test set\n",
    "\n",
    "# Standardize the data\n",
    "# Note: TabNet can handle raw data, but standardization may help in some cases.\n",
    "# You can comment this out if you prefer to use raw data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays of type float32 for PyTorch\n",
    "X_train_np = X_train.astype(np.float32)\n",
    "X_test_np = X_test.astype(np.float32)\n",
    "\n",
    "print(f\"Prepared X_train shape: {X_train_np.shape}\")\n",
    "print(f\"Prepared X_test shape: {X_test_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights: [ 1.       11.386959] to emphasize minority class\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights inversely proportional to class frequencies\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = len(y_train)\n",
    "# More aggressive weighting for minority class\n",
    "class_weights = torch.tensor([1.0, (class_counts[0]/class_counts[1]) * 1.0], dtype=torch.float32)\n",
    "if device_name == 'cuda':\n",
    "    class_weights = class_weights.cuda()\n",
    "\n",
    "print(f\"Using class weights: {class_weights.cpu().numpy()} to emphasize minority class\")\n",
    "\n",
    "# Create weighted loss function\n",
    "weighted_loss = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Baseline TabNet highest Model without CV...\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n",
      "Current CUDA device: 0\n",
      "Using device: cuda for TabNet model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet highest model initialized on cuda\n",
      "Fitting baseline TabNet highest model...\n",
      "epoch 0  | loss: 1.8517  | validation_auc: 0.50349 | validation_balanced_accuracy: 0.4988  |  0:00:26s\n",
      "epoch 1  | loss: 1.86325 | validation_auc: 0.50771 | validation_balanced_accuracy: 0.50559 |  0:00:53s\n",
      "epoch 2  | loss: 1.93116 | validation_auc: 0.52353 | validation_balanced_accuracy: 0.51237 |  0:01:21s\n",
      "epoch 3  | loss: 3.38728 | validation_auc: 0.50084 | validation_balanced_accuracy: 0.49437 |  0:01:54s\n",
      "epoch 4  | loss: 4.73964 | validation_auc: 0.52667 | validation_balanced_accuracy: 0.50723 |  0:02:26s\n",
      "epoch 5  | loss: 1.64124 | validation_auc: 0.50138 | validation_balanced_accuracy: 0.50525 |  0:02:58s\n",
      "epoch 6  | loss: 0.84107 | validation_auc: 0.57012 | validation_balanced_accuracy: 0.5553  |  0:03:31s\n",
      "epoch 7  | loss: 0.70626 | validation_auc: 0.54741 | validation_balanced_accuracy: 0.53703 |  0:04:03s\n",
      "epoch 8  | loss: 0.7033  | validation_auc: 0.57822 | validation_balanced_accuracy: 0.55863 |  0:04:36s\n",
      "epoch 9  | loss: 0.68202 | validation_auc: 0.59314 | validation_balanced_accuracy: 0.56309 |  0:05:08s\n",
      "epoch 10 | loss: 0.65143 | validation_auc: 0.70043 | validation_balanced_accuracy: 0.65155 |  0:05:41s\n",
      "epoch 11 | loss: 0.62995 | validation_auc: 0.61971 | validation_balanced_accuracy: 0.56968 |  0:06:14s\n",
      "epoch 12 | loss: 0.62982 | validation_auc: 0.70482 | validation_balanced_accuracy: 0.64795 |  0:06:43s\n",
      "epoch 13 | loss: 0.62419 | validation_auc: 0.71144 | validation_balanced_accuracy: 0.65527 |  0:07:10s\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize and Train a Baseline TabNet Model ---\n",
    "print(\"\\nTraining Baseline TabNet highest Model without CV...\")\n",
    "\n",
    "# First, explicitly check and print GPU information\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    # Force CUDA device if available\n",
    "    device_name = 'cuda'\n",
    "else:\n",
    "    print(\"Warning: CUDA not available, using CPU\")\n",
    "    device_name = 'cpu'\n",
    "\n",
    "# Make sure TABNET_PARAMS has device_name set correctly\n",
    "TABNET_PARAMS['device_name'] = device_name\n",
    "print(f\"Using device: {device_name} for TabNet model\")\n",
    "\n",
    "# Split off a small portion of the training data for validation (early stopping purposes)\n",
    "X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n",
    "    X_train_np, y_train, test_size=0.20, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "# Initialize the TabNet model with the parameters defined in TABNET_PARAMS\n",
    "tabnet_baseline = TabNetClassifier(**TABNET_PARAMS)\n",
    "print(f\"TabNet highest model initialized on {device_name}\")\n",
    "\n",
    "# Train the model with early stopping based on validation set\n",
    "print(\"Fitting baseline TabNet highest model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "tabnet_baseline.fit(\n",
    "    X_train=X_train_base, y_train=y_train_base,\n",
    "    eval_set=[(X_val_base, y_val_base)],\n",
    "    eval_name=['validation'],\n",
    "    eval_metric=['auc', 'balanced_accuracy'],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    virtual_batch_size=VIRTUAL_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    "    loss_fn=weighted_loss,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Baseline model training completed in {(end_time - start_time):.2f} seconds.\")\n",
    "\n",
    "# Make predictions\n",
    "baseline_preds = tabnet_baseline.predict_proba(X_test_np)[:, 1]\n",
    "baseline_binary_preds = (baseline_preds > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "print(\"\\n--- Baseline TabNet Model Evaluation ---\")\n",
    "baseline_results = evaluate_model(\n",
    "    y_test, baseline_preds, baseline_binary_preds, model_name=\"TabNet_highest (Baseline)\"\n",
    ")\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, baseline_preds, \"TabNet_highest (Baseline)\")\n",
    "\n",
    "# Save the model\n",
    "baseline_model_path = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_highest_baseline_model\")\n",
    "saved_baseline_path = tabnet_baseline.save_model(baseline_model_path)\n",
    "print(f\"Baseline model saved to {saved_baseline_path}\")\n",
    "\n",
    "# Save baseline results\n",
    "baseline_results_df = pd.DataFrame([baseline_results])\n",
    "baseline_results_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_highest_baseline_results.csv\")\n",
    "baseline_results_df.to_csv(baseline_results_filename, index=False, mode='w+')\n",
    "print(f\"Baseline results saved to {baseline_results_filename}\")\n",
    "\n",
    "# Feature importance from baseline model\n",
    "baseline_importance = tabnet_baseline.feature_importances_\n",
    "baseline_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': baseline_importance})\n",
    "baseline_importance_df = baseline_importance_df.sort_values(by='Importance', ascending=False)\n",
    "baseline_importance_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_highest_baseline_feature_importance.csv\")\n",
    "baseline_importance_df.to_csv(baseline_importance_filename, index=False, mode='w+')\n",
    "print(f\"Baseline feature importance saved to {baseline_importance_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal threshold using the validation set\n",
    "optimal_threshold = find_optimal_threshold_j_statistic(y_val_base, tabnet_baseline.predict_proba(X_val_base)[:, 1])\n",
    "print(f\"Optimal threshold for validation set: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Apply the optimal threshold to the test set predictions\n",
    "baseline_binary_preds_optimal = (baseline_preds > optimal_threshold).astype(int)\n",
    "# Evaluate the model with the optimal threshold\n",
    "print(\"\\n--- Baseline TabNet Model Evaluation with Optimal Threshold ---\")\n",
    "baseline_results_optimal = evaluate_model(\n",
    "    y_test, baseline_preds, baseline_binary_preds_optimal, model_name=\"TabNet_Highest (Baseline with Optimal Threshold)\"\n",
    ")\n",
    "\n",
    "# Save the results with the optimal threshold\n",
    "baseline_results_optimal_df = pd.DataFrame([baseline_results_optimal])\n",
    "baseline_results_optimal_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_highest_baseline_results_optimal.csv\")\n",
    "baseline_results_optimal_df.to_csv(baseline_results_optimal_filename, index=False, mode='w+')\n",
    "print(f\"Baseline results with optimal threshold saved to {baseline_results_optimal_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
