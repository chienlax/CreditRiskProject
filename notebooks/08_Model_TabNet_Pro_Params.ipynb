{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- Sklearn ---\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, brier_score_loss, log_loss, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# --- TabNet & PyTorch ---\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Utility functions + Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (can be imported from a utils file or redefined) ---\n",
    "def calculate_ks(y_true, y_Prob):\n",
    "    \"\"\"Calculates the Kolmogorov-Smirnov (KS) statistic.\"\"\"\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_Prob': y_Prob})\n",
    "    df = df.sort_values(by='y_Prob', ascending=False)\n",
    "    # Ensure y_true sums are not zero before division\n",
    "    sum_true = df['y_true'].sum()\n",
    "    sum_false = len(df) - sum_true\n",
    "    if sum_true == 0 or sum_false == 0:\n",
    "        return 0.0 # KS is 0 if one class is missing\n",
    "    df['cumulative_true'] = df['y_true'].cumsum() / sum_true\n",
    "    df['cumulative_false'] = (1 - df['y_true']).cumsum() / sum_false\n",
    "    ks = max(abs(df['cumulative_true'] - df['cumulative_false']))\n",
    "    return ks\n",
    "\n",
    "def find_optimal_threshold_j_statistic(y_true, y_Prob_oof):\n",
    "    \"\"\"Finds the optimal threshold maximizing Youden's J statistic (Sensitivity + Specificity - 1).\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_Prob_oof)\n",
    "     # Handle cases where thresholds might not be strictly decreasing\n",
    "    valid_indices = np.where(np.isfinite(thresholds))[0]\n",
    "    if len(valid_indices) == 0:\n",
    "        print(\"Warning: No valid thresholds found for J-statistic calculation.\")\n",
    "        return 0.5 # Default fallback\n",
    "    fpr, tpr, thresholds = fpr[valid_indices], tpr[valid_indices], thresholds[valid_indices]\n",
    "\n",
    "    if len(thresholds) == 0:\n",
    "         print(\"Warning: Threshold array is empty after filtering.\")\n",
    "         return 0.5\n",
    "\n",
    "    j_statistic = tpr - fpr\n",
    "    optimal_idx = np.argmax(j_statistic)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    # Ensure threshold is within [0, 1] bounds if necessary due to floating point issues\n",
    "    optimal_threshold = max(0.0, min(1.0, optimal_threshold))\n",
    "    print(f\"Optimal threshold based on Youden's J-Statistic (OOF): {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def evaluate_model(y_true, y_pred_Proba, y_pred_binary, model_name=\"Model\"):\n",
    "    \"\"\"Calculates and prints standard classification metrics.\"\"\"\n",
    "    # Add epsilon to Probabilities for log_loss if necessary\n",
    "    eps = 1e-15\n",
    "    y_pred_Proba = np.clip(y_pred_Proba, eps, 1 - eps)\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred_Proba)\n",
    "    gini = 2 * auc_roc - 1\n",
    "    ks = calculate_ks(y_true, y_pred_Proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "    brier = brier_score_loss(y_true, y_pred_Proba)\n",
    "    logloss = log_loss(y_true, y_pred_Proba)\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "    print(f\"\\n--- Evaluation Metrics for {model_name} ---\")\n",
    "    print(f\"AUC ROC:        {auc_roc:.4f}\")\n",
    "    print(f\"Gini Coefficient: {gini:.4f}\")\n",
    "    print(f\"KS Statistic:   {ks:.4f}\")\n",
    "    print(f\"Accuracy:       {accuracy:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall (TPR):   {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"Brier Score:    {brier:.4f}\")\n",
    "    print(f\"Log Loss:       {logloss:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'AUC': auc_roc, 'Gini': gini, 'KS': ks, 'Accuracy': accuracy,\n",
    "        'Precision': precision, 'Recall': recall, 'F1': f1,\n",
    "        'Brier': brier, 'LogLoss': logloss\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def plot_roc_curve(y_true, y_Prob, model_name):\n",
    "    \"\"\"Plots the ROC curve.\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_Prob)\n",
    "    auc_roc = roc_auc_score(y_true, y_Prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_roc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} - ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Save the plot\n",
    "    plot_filename = f\"roc_curve_{model_name.replace(' ', '_')}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"ROC curve saved to {plot_filename}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "DATA_PATH = '../data/Processed/'\n",
    "MODEL_OUTPUT_PATH = './tabnet_outputs/' # Directory to save model/results\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'TARGET'\n",
    "ID_COL = 'SK_ID_CURR'\n",
    "\n",
    "# --- Check for GPU ---\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data and PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preProcessed data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "print(\"Loading preProcessed data...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(DATA_PATH + 'train_final.csv')\n",
    "    test_df = pd.read_csv(DATA_PATH + 'test_final.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure 'train.csv' and 'test.csv' are in {DATA_PATH}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data ---\n",
    "y_train = train_df[TARGET].values # Use .values for numpy arrays\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "# Drop Target and potentially ID\n",
    "if ID_COL in train_df.columns:\n",
    "    X_train = train_df.drop(columns=[TARGET, ID_COL])\n",
    "    X_test = test_df.drop(columns=[TARGET, ID_COL])\n",
    "else:\n",
    "    X_train = train_df.drop(columns=[TARGET])\n",
    "    X_test = test_df.drop(columns=[TARGET])\n",
    "\n",
    "# Align columns just in case\n",
    "common_cols = list(X_train.columns.intersection(X_test.columns))\n",
    "X_train = X_train[common_cols]\n",
    "X_test = X_test[common_cols]\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\n",
      "Prepared X_train shape: (246005, 773)\n",
      "Prepared X_test shape: (61502, 773)\n"
     ]
    }
   ],
   "source": [
    "# --- LIMITATION: Treat all features as numerical ---\n",
    "# Ideally, identify original categorical features and pass their indices to TabNet.\n",
    "# Since we are using pre-encoded data, we treat all as numerical.\n",
    "print(\"WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\")\n",
    "categorical_indices = [] # No categorical indices Provided\n",
    "categorical_dims = [] # No specific dimensions needed if indices are empty\n",
    "\n",
    "# Handle infinite values and NaNs\n",
    "# Replace inf with NaN, then fill NaN with median of each column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(X_train.median())\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(X_train.median()) # Use train median for test set\n",
    "\n",
    "# Standardize the data\n",
    "# Note: TabNet can handle raw data, but standardization may help in some cases.\n",
    "# You can comment this out if you prefer to use raw data.\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays of type float32 for PyTorch\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "print(f\"Prepared X_train shape: {X_train_np.shape}\")\n",
    "print(f\"Prepared X_test shape: {X_test_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights: [ 1.       11.386959] to emphasize minority class\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights inversely Proportional to class frequencies\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = len(y_train)\n",
    "class_weights = torch.tensor([1.0, (class_counts[0]/class_counts[1]) * 1], dtype=torch.float32)\n",
    "if device_name == 'cuda':\n",
    "    class_weights = class_weights.cuda()\n",
    "\n",
    "print(f\"Using class weights: {class_weights.cpu().numpy()} to emphasize minority class\")\n",
    "\n",
    "weighted_loss = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Baseline TabNet Pro Model without CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet Pro model initialized on cuda\n",
      "Fitting baseline TabNet Pro model...\n",
      "epoch 0  | loss: 2.02976 | validation_logloss: 2.19913 | validation_auc: 0.50095 | validation_accuracy: 0.37438 | validation_balanced_accuracy: 0.5     |  0:00:06s\n",
      "epoch 1  | loss: 1.26993 | validation_logloss: 1.49499 | validation_auc: 0.49326 | validation_accuracy: 0.62924 | validation_balanced_accuracy: 0.49818 |  0:00:12s\n",
      "epoch 2  | loss: 1.15017 | validation_logloss: 1.2532  | validation_auc: 0.50115 | validation_accuracy: 0.69009 | validation_balanced_accuracy: 0.50085 |  0:00:17s\n",
      "epoch 3  | loss: 1.09973 | validation_logloss: 0.93501 | validation_auc: 0.50632 | validation_accuracy: 0.66641 | validation_balanced_accuracy: 0.506   |  0:00:23s\n",
      "epoch 4  | loss: 1.04728 | validation_logloss: 0.86799 | validation_auc: 0.49773 | validation_accuracy: 0.64125 | validation_balanced_accuracy: 0.49599 |  0:00:29s\n",
      "epoch 5  | loss: 1.00883 | validation_logloss: 0.79257 | validation_auc: 0.50662 | validation_accuracy: 0.66464 | validation_balanced_accuracy: 0.50779 |  0:00:35s\n",
      "epoch 6  | loss: 0.98922 | validation_logloss: 0.81829 | validation_auc: 0.51422 | validation_accuracy: 0.6035  | validation_balanced_accuracy: 0.50727 |  0:00:41s\n",
      "epoch 7  | loss: 0.96104 | validation_logloss: 0.75926 | validation_auc: 0.53143 | validation_accuracy: 0.63005 | validation_balanced_accuracy: 0.51642 |  0:00:47s\n",
      "epoch 8  | loss: 0.92952 | validation_logloss: 0.75572 | validation_auc: 0.55516 | validation_accuracy: 0.62972 | validation_balanced_accuracy: 0.53691 |  0:00:53s\n",
      "epoch 9  | loss: 0.90008 | validation_logloss: 0.7392  | validation_auc: 0.56248 | validation_accuracy: 0.59741 | validation_balanced_accuracy: 0.53725 |  0:00:58s\n",
      "epoch 10 | loss: 0.87263 | validation_logloss: 0.71018 | validation_auc: 0.56824 | validation_accuracy: 0.60084 | validation_balanced_accuracy: 0.54141 |  0:01:04s\n",
      "epoch 11 | loss: 0.86157 | validation_logloss: 0.7217  | validation_auc: 0.57378 | validation_accuracy: 0.5894  | validation_balanced_accuracy: 0.54518 |  0:01:10s\n",
      "epoch 12 | loss: 0.84758 | validation_logloss: 0.71643 | validation_auc: 0.58737 | validation_accuracy: 0.57716 | validation_balanced_accuracy: 0.56046 |  0:01:16s\n",
      "epoch 13 | loss: 0.83228 | validation_logloss: 0.68178 | validation_auc: 0.59122 | validation_accuracy: 0.61649 | validation_balanced_accuracy: 0.55957 |  0:01:22s\n",
      "epoch 14 | loss: 0.81521 | validation_logloss: 0.67354 | validation_auc: 0.60254 | validation_accuracy: 0.6257  | validation_balanced_accuracy: 0.56653 |  0:01:28s\n",
      "epoch 15 | loss: 0.80733 | validation_logloss: 0.68248 | validation_auc: 0.60441 | validation_accuracy: 0.60765 | validation_balanced_accuracy: 0.56854 |  0:01:34s\n",
      "epoch 16 | loss: 0.79909 | validation_logloss: 0.66816 | validation_auc: 0.62019 | validation_accuracy: 0.62846 | validation_balanced_accuracy: 0.58158 |  0:01:40s\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize and Train a Baseline TabNet Model ---\n",
    "print(\"\\nTraining Baseline TabNet Pro Model without CV...\")\n",
    "\n",
    "TABNET_PARAMS = dict(\n",
    "    n_d=128, n_a=128, n_steps=6, n_independent=2, n_shared=2,\n",
    "    mask_type='sparsemax', gamma=1.7, lambda_sparse=0.001,\n",
    "    optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=0.0005),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params=dict(\n",
    "        mode=\"max\", patience=20, min_lr=1e-6, factor=0.95),\n",
    "    verbose=1, seed=SEED, clip_value=1.0, device_name=device_name,\n",
    ")\n",
    "\n",
    "MAX_EPOCHS = 3000\n",
    "PATIENCE = 100\n",
    "BATCH_SIZE = 8192\n",
    "VIRTUAL_BATCH_SIZE = 2048\n",
    "\n",
    "X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n",
    "    X_train_np, y_train, test_size=0.20, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "tabnet_baseline = TabNetClassifier(**TABNET_PARAMS)\n",
    "print(f\"TabNet Pro model initialized on {device_name}\")\n",
    "print(\"Fitting baseline TabNet Pro model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "tabnet_baseline.fit(\n",
    "    X_train=X_train_base, y_train=y_train_base,\n",
    "    eval_set=[(X_val_base, y_val_base)],\n",
    "    eval_name=['validation'],\n",
    "    eval_metric=['logloss','auc', 'accuracy', 'balanced_accuracy'],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    virtual_batch_size=VIRTUAL_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    "    loss_fn=weighted_loss,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Baseline model training completed in {(end_time - start_time):.2f} seconds.\")\n",
    "\n",
    "# Make predictions\n",
    "baseline_preds = tabnet_baseline.predict_proba(X_test_np)[:, 1]\n",
    "baseline_binary_preds = (baseline_preds > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "print(\"\\n--- Baseline TabNet Model Evaluation ---\")\n",
    "baseline_results = evaluate_model(\n",
    "    y_test, baseline_preds, baseline_binary_preds, model_name=\"TabNet_Pro (Baseline)\"\n",
    ")\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, baseline_preds, \"TabNet_Pro (Baseline)\")\n",
    "\n",
    "# Save the model\n",
    "baseline_model_path = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_Pro_baseline_model\")\n",
    "saved_baseline_path = tabnet_baseline.save_model(baseline_model_path)\n",
    "print(f\"Baseline model saved to {saved_baseline_path}\")\n",
    "\n",
    "# Save baseline results\n",
    "baseline_results_df = pd.DataFrame([baseline_results])\n",
    "baseline_results_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_Pro_baseline_results.csv\")\n",
    "baseline_results_df.to_csv(baseline_results_filename, index=False, mode='w+')\n",
    "print(f\"Baseline results saved to {baseline_results_filename}\")\n",
    "\n",
    "# Feature importance from baseline model\n",
    "baseline_importance = tabnet_baseline.feature_importances_\n",
    "baseline_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': baseline_importance})\n",
    "baseline_importance_df = baseline_importance_df.sort_values(by='Importance', ascending=False)\n",
    "baseline_importance_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_Pro_baseline_feature_importance.csv\")\n",
    "baseline_importance_df.to_csv(baseline_importance_filename, index=False, mode='w+')\n",
    "print(f\"Baseline feature importance saved to {baseline_importance_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold based on Youden's J-Statistic (OOF): 0.5025\n",
      "Optimal threshold for validation set: 0.5025\n",
      "\n",
      "--- Baseline TabNet Model Evaluation with Optimal Threshold ---\n",
      "\n",
      "--- Evaluation Metrics for TabNet_Pro (Baseline with Optimal Threshold) ---\n",
      "AUC ROC:        0.7349\n",
      "Gini Coefficient: 0.4699\n",
      "KS Statistic:   0.3509\n",
      "Accuracy:       0.6849\n",
      "Precision:      0.1559\n",
      "Recall (TPR):   0.6578\n",
      "F1-Score:       0.2521\n",
      "Brier Score:    0.2067\n",
      "Log Loss:       0.6010\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38858 17679]\n",
      " [ 1699  3266]]\n",
      "Baseline results with optimal threshold saved to ./tabnet_outputs/tabnet_Pro_baseline_results_optimal.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal threshold using the validation set\n",
    "optimal_threshold = find_optimal_threshold_j_statistic(y_val_base, tabnet_baseline.predict_proba(X_val_base)[:, 1])\n",
    "print(f\"Optimal threshold for validation set: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Apply the optimal threshold to the test set predictions\n",
    "baseline_binary_preds_optimal = (baseline_preds > optimal_threshold).astype(int)\n",
    "# Evaluate the model with the optimal threshold\n",
    "print(\"\\n--- Baseline TabNet Model Evaluation with Optimal Threshold ---\")\n",
    "baseline_results_optimal = evaluate_model(\n",
    "    y_test, baseline_preds, baseline_binary_preds_optimal, model_name=\"TabNet_Pro (Baseline with Optimal Threshold)\"\n",
    ")\n",
    "\n",
    "# Save the results with the optimal threshold\n",
    "baseline_results_optimal_df = pd.DataFrame([baseline_results_optimal])\n",
    "baseline_results_optimal_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_Pro_baseline_results_optimal.csv\")\n",
    "baseline_results_optimal_df.to_csv(baseline_results_optimal_filename, index=False, mode='w+')\n",
    "print(f\"Baseline results with optimal threshold saved to {baseline_results_optimal_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
