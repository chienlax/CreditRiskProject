{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- Sklearn ---\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, brier_score_loss, log_loss, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# --- TabNet & PyTorch ---\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Utility functions + Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (can be imported from a utils file or redefined) ---\n",
    "def calculate_ks(y_true, y_prob):\n",
    "    \"\"\"Calculates the Kolmogorov-Smirnov (KS) statistic.\"\"\"\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "    df = df.sort_values(by='y_prob', ascending=False)\n",
    "    # Ensure y_true sums are not zero before division\n",
    "    sum_true = df['y_true'].sum()\n",
    "    sum_false = len(df) - sum_true\n",
    "    if sum_true == 0 or sum_false == 0:\n",
    "        return 0.0 # KS is 0 if one class is missing\n",
    "    df['cumulative_true'] = df['y_true'].cumsum() / sum_true\n",
    "    df['cumulative_false'] = (1 - df['y_true']).cumsum() / sum_false\n",
    "    ks = max(abs(df['cumulative_true'] - df['cumulative_false']))\n",
    "    return ks\n",
    "\n",
    "def find_optimal_threshold_j_statistic(y_true, y_prob_oof):\n",
    "    \"\"\"Finds the optimal threshold maximizing Youden's J statistic (Sensitivity + Specificity - 1).\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob_oof)\n",
    "     # Handle cases where thresholds might not be strictly decreasing\n",
    "    valid_indices = np.where(np.isfinite(thresholds))[0]\n",
    "    if len(valid_indices) == 0:\n",
    "        print(\"Warning: No valid thresholds found for J-statistic calculation.\")\n",
    "        return 0.5 # Default fallback\n",
    "    fpr, tpr, thresholds = fpr[valid_indices], tpr[valid_indices], thresholds[valid_indices]\n",
    "\n",
    "    if len(thresholds) == 0:\n",
    "         print(\"Warning: Threshold array is empty after filtering.\")\n",
    "         return 0.5\n",
    "\n",
    "    j_statistic = tpr - fpr\n",
    "    optimal_idx = np.argmax(j_statistic)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    # Ensure threshold is within [0, 1] bounds if necessary due to floating point issues\n",
    "    optimal_threshold = max(0.0, min(1.0, optimal_threshold))\n",
    "    print(f\"Optimal threshold based on Youden's J-Statistic (OOF): {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def evaluate_model(y_true, y_pred_proba, y_pred_binary, model_name=\"Model\"):\n",
    "    \"\"\"Calculates and prints standard classification metrics.\"\"\"\n",
    "    # Add epsilon to probabilities for log_loss if necessary\n",
    "    eps = 1e-15\n",
    "    y_pred_proba = np.clip(y_pred_proba, eps, 1 - eps)\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
    "    gini = 2 * auc_roc - 1\n",
    "    ks = calculate_ks(y_true, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_binary, zero_division=0)\n",
    "    brier = brier_score_loss(y_true, y_pred_proba)\n",
    "    logloss = log_loss(y_true, y_pred_proba)\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "    print(f\"\\n--- Evaluation Metrics for {model_name} ---\")\n",
    "    print(f\"AUC ROC:        {auc_roc:.4f}\")\n",
    "    print(f\"Gini Coefficient: {gini:.4f}\")\n",
    "    print(f\"KS Statistic:   {ks:.4f}\")\n",
    "    print(f\"Accuracy:       {accuracy:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall (TPR):   {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"Brier Score:    {brier:.4f}\")\n",
    "    print(f\"Log Loss:       {logloss:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'AUC': auc_roc, 'Gini': gini, 'KS': ks, 'Accuracy': accuracy,\n",
    "        'Precision': precision, 'Recall': recall, 'F1': f1,\n",
    "        'Brier': brier, 'LogLoss': logloss\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def plot_roc_curve(y_true, y_prob, model_name):\n",
    "    \"\"\"Plots the ROC curve.\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_roc = roc_auc_score(y_true, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_roc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Diagonal line\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} - ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Save the plot\n",
    "    plot_filename = f\"roc_curve_{model_name.replace(' ', '_')}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"ROC curve saved to {plot_filename}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "DATA_PATH = '../data/processed/'\n",
    "MODEL_OUTPUT_PATH = './tabnet_outputs/' # Directory to save model/results\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "SEED = 42\n",
    "N_SPLITS = 10\n",
    "TARGET = 'TARGET'\n",
    "ID_COL = 'SK_ID_CURR'\n",
    "\n",
    "# TabNet Specific Config\n",
    "TABNET_PARAMS = dict(\n",
    "    # Network architecture\n",
    "    n_d=128,             \n",
    "    n_a=128,              \n",
    "    n_steps=10,          \n",
    "    n_independent=4,    \n",
    "    n_shared=4,     \n",
    "    \n",
    "    # Regularization\n",
    "    gamma=1.5,         \n",
    "    lambda_sparse=5e-4, \n",
    "    \n",
    "    # Optimizer settings\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler_params=dict(\n",
    "        mode=\"min\", \n",
    "        patience=50,    \n",
    "        min_lr=1e-4, \n",
    "        factor=0.5\n",
    "    ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \n",
    "    mask_type='sparsemax',\n",
    "    verbose=1,\n",
    "    seed=42 \n",
    ")\n",
    "\n",
    "# Training Config\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE = 50\n",
    "BATCH_SIZE = 4096\n",
    "VIRTUAL_BATCH_SIZE = 1024\n",
    "\n",
    "# --- Check for GPU ---\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "print(\"Loading preprocessed data...\")\n",
    "try:\n",
    "    train_df = pd.read_csv(DATA_PATH + 'train_final.csv')\n",
    "    test_df = pd.read_csv(DATA_PATH + 'test_final.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure 'train_final.csv' and 'test_final.csv' are in {DATA_PATH}\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Data ---\n",
    "y_train = train_df[TARGET].values # Use .values for numpy arrays\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "# Drop Target and potentially ID\n",
    "if ID_COL in train_df.columns:\n",
    "    X_train = train_df.drop(columns=[TARGET, ID_COL])\n",
    "    X_test = test_df.drop(columns=[TARGET, ID_COL])\n",
    "else:\n",
    "    X_train = train_df.drop(columns=[TARGET])\n",
    "    X_test = test_df.drop(columns=[TARGET])\n",
    "\n",
    "# Align columns just in case\n",
    "common_cols = list(X_train.columns.intersection(X_test.columns))\n",
    "X_train = X_train[common_cols]\n",
    "X_test = X_test[common_cols]\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Low Variance Feature Selection...\n",
      "Original number of features: 773\n",
      "Number of features after variance thresholding: 542\n",
      "Updated X_train shape: (246005, 542)\n",
      "Updated X_test shape: (61502, 542)\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Selection: Low Variance Filter ---\n",
    "print(\"\\nApplying Low Variance Feature Selection...\")\n",
    "var_selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Fit on training data only\n",
    "var_selector.fit(X_train)\n",
    "\n",
    "# Get the boolean mask of selected features\n",
    "feature_mask = var_selector.get_support()\n",
    "original_feature_names = X_train.columns.tolist() # Get original names before transformation\n",
    "selected_feature_names = [name for name, selected in zip(original_feature_names, feature_mask) if selected]\n",
    "\n",
    "print(f\"Original number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features after variance thresholding: {len(selected_feature_names)}\")\n",
    "\n",
    "# Transform both X_train and X_test\n",
    "X_train_np_selected = var_selector.transform(X_train)\n",
    "X_test_np_selected = var_selector.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame with selected column names\n",
    "X_train = pd.DataFrame(X_train_np_selected, columns=selected_feature_names, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_np_selected, columns=selected_feature_names, index=X_test.index)\n",
    "\n",
    "# Update the global feature_names list\n",
    "feature_names = selected_feature_names\n",
    "\n",
    "print(f\"Updated X_train shape: {X_train.shape}\")\n",
    "print(f\"Updated X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\n",
      "Prepared X_train shape: (246005, 542)\n",
      "Prepared X_test shape: (61502, 542)\n"
     ]
    }
   ],
   "source": [
    "# --- LIMITATION: Treat all features as numerical ---\n",
    "# Ideally, identify original categorical features and pass their indices to TabNet.\n",
    "# Since we are using pre-encoded data, we treat all as numerical.\n",
    "print(\"WARNING: Treating all features as numerical for TabNet due to pre-encoded input data.\")\n",
    "categorical_indices = [] # No categorical indices provided\n",
    "categorical_dims = [] # No specific dimensions needed if indices are empty\n",
    "\n",
    "# Handle infinite values and NaNs\n",
    "# Replace inf with NaN, then fill NaN with median of each column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(X_train.median())\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(X_train.median()) # Use train median for test set\n",
    "\n",
    "# Standardize the data\n",
    "# Note: TabNet can handle raw data, but standardization may help in some cases.\n",
    "# You can comment this out if you prefer to use raw data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays of type float32 for PyTorch\n",
    "X_train_np = X_train.astype(np.float32)\n",
    "X_test_np = X_test.astype(np.float32)\n",
    "\n",
    "print(f\"Prepared X_train shape: {X_train_np.shape}\")\n",
    "print(f\"Prepared X_test shape: {X_test_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights: [ 1.       11.386959] to emphasize minority class\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights inversely proportional to class frequencies\n",
    "class_counts = np.bincount(y_train)\n",
    "total_samples = len(y_train)\n",
    "# More aggressive weighting for minority class\n",
    "class_weights = torch.tensor([1.0, (class_counts[0]/class_counts[1]) * 1.0], dtype=torch.float32)\n",
    "if device_name == 'cuda':\n",
    "    class_weights = class_weights.cuda()\n",
    "\n",
    "print(f\"Using class weights: {class_weights.cpu().numpy()} to emphasize minority class\")\n",
    "\n",
    "# Create weighted loss function\n",
    "weighted_loss = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Baseline TabNet High Model without CV...\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n",
      "Current CUDA device: 0\n",
      "Using device: cuda for TabNet model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet High model initialized on cuda\n",
      "Fitting baseline TabNet High model...\n",
      "epoch 0  | loss: 1.5327  | validation_auc: 0.5237  | validation_balanced_accuracy: 0.50278 |  0:00:24s\n",
      "epoch 1  | loss: 1.41418 | validation_auc: 0.49327 | validation_balanced_accuracy: 0.5     |  0:00:49s\n",
      "epoch 2  | loss: 0.72478 | validation_auc: 0.5984  | validation_balanced_accuracy: 0.57085 |  0:01:12s\n",
      "epoch 3  | loss: 0.69265 | validation_auc: 0.56627 | validation_balanced_accuracy: 0.54902 |  0:01:35s\n",
      "epoch 4  | loss: 0.69435 | validation_auc: 0.57529 | validation_balanced_accuracy: 0.55111 |  0:01:59s\n",
      "epoch 5  | loss: 0.684   | validation_auc: 0.59804 | validation_balanced_accuracy: 0.56724 |  0:02:23s\n",
      "epoch 6  | loss: 0.66876 | validation_auc: 0.66019 | validation_balanced_accuracy: 0.62173 |  0:02:47s\n",
      "epoch 7  | loss: 0.64493 | validation_auc: 0.69062 | validation_balanced_accuracy: 0.64722 |  0:03:11s\n",
      "epoch 8  | loss: 0.62818 | validation_auc: 0.71377 | validation_balanced_accuracy: 0.65934 |  0:03:35s\n",
      "epoch 9  | loss: 0.6168  | validation_auc: 0.72756 | validation_balanced_accuracy: 0.6716  |  0:04:00s\n",
      "epoch 10 | loss: 0.61052 | validation_auc: 0.72994 | validation_balanced_accuracy: 0.67215 |  0:04:24s\n",
      "epoch 11 | loss: 0.60645 | validation_auc: 0.73063 | validation_balanced_accuracy: 0.67036 |  0:04:48s\n",
      "epoch 12 | loss: 0.60404 | validation_auc: 0.73726 | validation_balanced_accuracy: 0.67779 |  0:05:13s\n",
      "epoch 13 | loss: 0.6046  | validation_auc: 0.72984 | validation_balanced_accuracy: 0.67117 |  0:05:37s\n",
      "epoch 14 | loss: 0.61478 | validation_auc: 0.7291  | validation_balanced_accuracy: 0.67189 |  0:06:01s\n",
      "epoch 15 | loss: 0.61165 | validation_auc: 0.72237 | validation_balanced_accuracy: 0.66689 |  0:06:26s\n",
      "epoch 16 | loss: 0.61199 | validation_auc: 0.72911 | validation_balanced_accuracy: 0.66939 |  0:06:50s\n",
      "epoch 17 | loss: 0.6095  | validation_auc: 0.72842 | validation_balanced_accuracy: 0.67012 |  0:07:13s\n",
      "epoch 18 | loss: 0.60859 | validation_auc: 0.73136 | validation_balanced_accuracy: 0.67228 |  0:07:37s\n",
      "epoch 19 | loss: 0.60482 | validation_auc: 0.73482 | validation_balanced_accuracy: 0.67721 |  0:08:00s\n",
      "epoch 20 | loss: 0.60488 | validation_auc: 0.73595 | validation_balanced_accuracy: 0.6747  |  0:08:25s\n",
      "epoch 21 | loss: 0.6024  | validation_auc: 0.73602 | validation_balanced_accuracy: 0.67659 |  0:08:49s\n",
      "epoch 22 | loss: 0.60697 | validation_auc: 0.73354 | validation_balanced_accuracy: 0.67392 |  0:09:14s\n",
      "epoch 23 | loss: 0.60132 | validation_auc: 0.73938 | validation_balanced_accuracy: 0.67788 |  0:09:44s\n",
      "epoch 24 | loss: 0.59832 | validation_auc: 0.73961 | validation_balanced_accuracy: 0.67704 |  0:10:14s\n",
      "epoch 25 | loss: 0.5971  | validation_auc: 0.74175 | validation_balanced_accuracy: 0.67841 |  0:10:44s\n",
      "epoch 26 | loss: 0.59461 | validation_auc: 0.74093 | validation_balanced_accuracy: 0.67967 |  0:11:14s\n",
      "epoch 27 | loss: 0.59312 | validation_auc: 0.74403 | validation_balanced_accuracy: 0.67712 |  0:11:44s\n",
      "epoch 28 | loss: 0.59099 | validation_auc: 0.7439  | validation_balanced_accuracy: 0.68092 |  0:12:13s\n",
      "epoch 29 | loss: 0.58983 | validation_auc: 0.74386 | validation_balanced_accuracy: 0.67839 |  0:12:44s\n",
      "epoch 30 | loss: 0.58865 | validation_auc: 0.74412 | validation_balanced_accuracy: 0.67889 |  0:13:10s\n",
      "epoch 31 | loss: 0.58732 | validation_auc: 0.7439  | validation_balanced_accuracy: 0.67929 |  0:13:40s\n",
      "epoch 32 | loss: 0.5843  | validation_auc: 0.74465 | validation_balanced_accuracy: 0.67659 |  0:14:09s\n",
      "epoch 33 | loss: 0.58324 | validation_auc: 0.74269 | validation_balanced_accuracy: 0.67805 |  0:14:39s\n",
      "epoch 34 | loss: 0.58358 | validation_auc: 0.7419  | validation_balanced_accuracy: 0.6771  |  0:15:08s\n",
      "epoch 35 | loss: 0.5806  | validation_auc: 0.73845 | validation_balanced_accuracy: 0.6767  |  0:15:38s\n",
      "epoch 36 | loss: 0.5948  | validation_auc: 0.73244 | validation_balanced_accuracy: 0.66743 |  0:16:02s\n",
      "epoch 37 | loss: 0.60893 | validation_auc: 0.7273  | validation_balanced_accuracy: 0.6708  |  0:16:27s\n",
      "epoch 38 | loss: 0.60768 | validation_auc: 0.73171 | validation_balanced_accuracy: 0.66809 |  0:16:56s\n",
      "epoch 39 | loss: 0.6016  | validation_auc: 0.73931 | validation_balanced_accuracy: 0.67816 |  0:17:26s\n",
      "epoch 40 | loss: 0.59512 | validation_auc: 0.74035 | validation_balanced_accuracy: 0.67877 |  0:17:55s\n",
      "epoch 41 | loss: 0.59078 | validation_auc: 0.74156 | validation_balanced_accuracy: 0.67887 |  0:18:25s\n",
      "epoch 42 | loss: 0.58624 | validation_auc: 0.74365 | validation_balanced_accuracy: 0.68206 |  0:18:54s\n",
      "epoch 43 | loss: 0.59154 | validation_auc: 0.72664 | validation_balanced_accuracy: 0.66303 |  0:19:17s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting baseline TabNet High model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mtabnet_baseline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_base\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mauc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbalanced_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVIRTUAL_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweighted_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m end_time = time.time()\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBaseline model training completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:258\u001b[39m, in \u001b[36mTabModel.fit\u001b[39m\u001b[34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_epochs):\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_epoch_begin(epoch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:489\u001b[39m, in \u001b[36mTabModel._train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m    487\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_begin(batch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     batch_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_end(batch_idx, batch_logs)\n\u001b[32m    493\u001b[39m epoch_logs = {\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._optimizer.param_groups[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ORLab\\main_source\\CreditRiskProject\\venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:539\u001b[39m, in \u001b[36mTabModel._train_batch\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    536\u001b[39m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.network.parameters(), \u001b[38;5;28mself\u001b[39m.clip_value)\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m batch_logs[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.detach().numpy().item()\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m batch_logs\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Initialize and Train a Baseline TabNet Model ---\n",
    "print(\"\\nTraining Baseline TabNet High Model without CV...\")\n",
    "\n",
    "# First, explicitly check and print GPU information\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    # Force CUDA device if available\n",
    "    device_name = 'cuda'\n",
    "else:\n",
    "    print(\"Warning: CUDA not available, using CPU\")\n",
    "    device_name = 'cpu'\n",
    "\n",
    "# Make sure TABNET_PARAMS has device_name set correctly\n",
    "TABNET_PARAMS['device_name'] = device_name\n",
    "print(f\"Using device: {device_name} for TabNet model\")\n",
    "\n",
    "# Split off a small portion of the training data for validation (early stopping purposes)\n",
    "X_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n",
    "    X_train_np, y_train, test_size=0.20, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "# Initialize the TabNet model with the parameters defined in TABNET_PARAMS\n",
    "tabnet_baseline = TabNetClassifier(**TABNET_PARAMS)\n",
    "print(f\"TabNet High model initialized on {device_name}\")\n",
    "\n",
    "# Train the model with early stopping based on validation set\n",
    "print(\"Fitting baseline TabNet High model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "tabnet_baseline.fit(\n",
    "    X_train=X_train_base, y_train=y_train_base,\n",
    "    eval_set=[(X_val_base, y_val_base)],\n",
    "    eval_name=['validation'],\n",
    "    eval_metric=['auc', 'balanced_accuracy'],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    virtual_batch_size=VIRTUAL_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    "    loss_fn=weighted_loss,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Baseline model training completed in {(end_time - start_time):.2f} seconds.\")\n",
    "\n",
    "# Make predictions\n",
    "baseline_preds = tabnet_baseline.predict_proba(X_test_np)[:, 1]\n",
    "baseline_binary_preds = (baseline_preds > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "print(\"\\n--- Baseline TabNet Model Evaluation ---\")\n",
    "baseline_results = evaluate_model(\n",
    "    y_test, baseline_preds, baseline_binary_preds, model_name=\"TabNet_High (Baseline)\"\n",
    ")\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(y_test, baseline_preds, \"TabNet (Baseline)\")\n",
    "\n",
    "# Save the model\n",
    "baseline_model_path = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_baseline_model\")\n",
    "saved_baseline_path = tabnet_baseline.save_model(baseline_model_path)\n",
    "print(f\"Baseline model saved to {saved_baseline_path}\")\n",
    "\n",
    "# Save baseline results\n",
    "baseline_results_df = pd.DataFrame([baseline_results])\n",
    "baseline_results_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_baseline_results.csv\")\n",
    "baseline_results_df.to_csv(baseline_results_filename, index=False, mode='w+')\n",
    "print(f\"Baseline results saved to {baseline_results_filename}\")\n",
    "\n",
    "# Feature importance from baseline model\n",
    "baseline_importance = tabnet_baseline.feature_importances_\n",
    "baseline_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': baseline_importance})\n",
    "baseline_importance_df = baseline_importance_df.sort_values(by='Importance', ascending=False)\n",
    "baseline_importance_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_baseline_feature_importance.csv\")\n",
    "baseline_importance_df.to_csv(baseline_importance_filename, index=False, mode='w+')\n",
    "print(f\"Baseline feature importance saved to {baseline_importance_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cross-Validation with Best Parameters ---\n",
    "print(\"\\nStarting TabNet High Cross-Validation with Best Parameters...\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "oof_predictions = np.zeros(X_train_np.shape[0]) # Store OOF predictions here\n",
    "test_predictions_list = [] # Store test predictions from each fold\n",
    "fold_models = [] # Store models from each fold (optional)\n",
    "fold_results = [] # Store validation AUC from each fold\n",
    "\n",
    "start_cv_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_np, y_train)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} ---\")\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    # 1. Split data for the fold (using pre-scaled data)\n",
    "    X_train_fold, X_val_fold = X_train_np[train_idx], X_train_np[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    model = TabNetClassifier(**TABNET_PARAMS)\n",
    "    print(f\"Training TabNet model on fold {fold+1}...\")\n",
    "    print(f\"Model initialized on {device_name}.\")\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train_fold, y_train=y_train_fold,\n",
    "        eval_set=[(X_val_fold, y_val_fold)],\n",
    "        eval_name=['validation'],\n",
    "        eval_metric=['auc', 'balanced_accuracy'],\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        virtual_batch_size=VIRTUAL_BATCH_SIZE, \n",
    "        num_workers=0, \n",
    "        drop_last=False,\n",
    "        loss_fn=weighted_loss\n",
    "    )\n",
    "\n",
    "    # 3. Predict on Validation and Test Sets\n",
    "    print(\"Predicting on validation and test sets...\")\n",
    "    # OOF prediction for this fold\n",
    "    val_preds = model.predict_proba(X_val_fold)[:, 1]\n",
    "    # Test prediction using this fold's model (on pre-scaled test data)\n",
    "    test_preds = model.predict_proba(X_test_np)[:, 1]\n",
    "\n",
    "    # 4. Store Predictions\n",
    "    oof_predictions[val_idx] = val_preds\n",
    "    test_predictions_list.append(test_preds)\n",
    "    fold_models.append(model) # Store the model\n",
    "\n",
    "    # 5. Evaluate Fold (optional but good practice)\n",
    "    fold_auc = roc_auc_score(y_val_fold, val_preds)\n",
    "    print(f\"Fold {fold+1} Validation AUC: {fold_auc:.4f}\")\n",
    "    fold_results.append({'Fold': fold+1, 'Validation AUC': fold_auc})\n",
    "\n",
    "    fold_end_time = time.time()\n",
    "    print(f\"Fold {fold+1} completed in {(fold_end_time - fold_start_time):.2f} seconds.\")\n",
    "\n",
    "end_cv_time = time.time()\n",
    "print(f\"\\nCross-Validation finished in {(end_cv_time - start_cv_time)/60:.2f} minutes.\")\n",
    "\n",
    "# --- Aggregate and Evaluate ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Evaluation (Based on Averaged CV Predictions)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Average test predictions across folds\n",
    "final_test_predictions = np.mean(test_predictions_list, axis=0)\n",
    "\n",
    "# Evaluate OOF predictions\n",
    "oof_auc = roc_auc_score(y_train, oof_predictions)\n",
    "print(f\"Overall OOF AUC: {oof_auc:.4f}\")\n",
    "\n",
    "# Find optimal threshold using OOF predictions\n",
    "optimal_threshold = find_optimal_threshold_j_statistic(y_train, oof_predictions)\n",
    "\n",
    "# Evaluate final test predictions using the optimal threshold\n",
    "final_test_predictions_binary = (final_test_predictions >= optimal_threshold).astype(int)\n",
    "\n",
    "# Store results in the 'tuned_results' list/DataFrame for consistency with 03_Model_ML\n",
    "tuned_results = [] # Initialize if not already done\n",
    "tuned_results.append(\n",
    "    evaluate_model(y_test, \n",
    "                   final_test_predictions, \n",
    "                   final_test_predictions_binary, \n",
    "                   \"TabNet High (Tuned CV)\"\n",
    "                   )\n",
    "                )\n",
    "\n",
    "# Plot ROC curve for the averaged test predictions\n",
    "plot_roc_curve(y_test, final_test_predictions, \"TabNet High (Tuned CV)\")\n",
    "\n",
    "# --- Feature Importance ---\n",
    "print(\"\\n--- TabNet High Feature Importances (from last fold model) ---\")\n",
    "try:\n",
    "    importances = fold_models[-1].feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "    display(feature_importance_df.head(50)) # Show top 50\n",
    "\n",
    "    # Save importances\n",
    "    importance_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_feature_importances.csv\") # Changed filename slightly\n",
    "    feature_importance_df.to_csv(importance_filename, index=False, mode='w+') # Use 'w' mode\n",
    "    print(f\"Feature importances saved to {importance_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not get or save feature importances: {e}\")\n",
    "\n",
    "# --- Save Results ---\n",
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# Save tuned results (consistent with 03_Model_ML)\n",
    "tuned_results_df = pd.DataFrame(tuned_results).set_index('Model')\n",
    "tuned_summary_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_model_results.csv\")\n",
    "tuned_results_df.to_csv(tuned_summary_filename, mode='w+') # Use 'w' mode\n",
    "print(f\"Tuned evaluation summary saved to {tuned_summary_filename}\")\n",
    "\n",
    "# Save OOF and Test predictions (Assuming train_df and test_df indices are available)\n",
    "# If train_df/test_df were overwritten by scaled numpy arrays, you might need IDs saved separately\n",
    "try:\n",
    "    oof_df = pd.DataFrame({'SK_ID_CURR': train_df[ID_COL], 'oof_pred_proba': oof_predictions}) # Use original train_df if available for ID\n",
    "    oof_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_oof_predictions.csv\") # Changed filename\n",
    "    oof_df.to_csv(oof_filename, index=False, mode='w+') # Use 'w' mode\n",
    "    print(f\"OOF predictions saved to {oof_filename}\")\n",
    "\n",
    "    test_pred_df = pd.DataFrame({'SK_ID_CURR': test_df[ID_COL], 'test_pred_proba': final_test_predictions}) # Use original test_df if available for ID\n",
    "    test_pred_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_test_predictions.csv\") # Changed filename\n",
    "    test_pred_df.to_csv(test_pred_filename, index=False, mode='w+') # Use 'w' mode\n",
    "    print(f\"Test predictions saved to {test_pred_filename}\")\n",
    "except NameError:\n",
    "    print(\"Warning: Original train_df/test_df with SK_ID_CURR not found. Saving predictions without IDs.\")\n",
    "    oof_df = pd.DataFrame({'oof_pred_proba': oof_predictions})\n",
    "    oof_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_oof_predictions.csv\") # Changed filename\n",
    "    oof_df.to_csv(oof_filename, index=False, mode='w+') # Use 'w' mode\n",
    "    print(f\"OOF predictions saved to {oof_filename}\")\n",
    "\n",
    "    test_pred_df = pd.DataFrame({'test_pred_proba': final_test_predictions}) # Assuming test_df index maps correctly\n",
    "    test_pred_filename = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_tuned_test_predictions.csv\") # Changed filename\n",
    "    test_pred_df.to_csv(test_pred_filename, index=False, mode='w+') # Use 'w' mode\n",
    "    print(f\"Test predictions saved to {test_pred_filename}\")\n",
    "\n",
    "# Optionally save one of the trained models (e.g., the last fold's)\n",
    "model_save_path = os.path.join(MODEL_OUTPUT_PATH, \"tabnet_high_model_last_fold\") # No need for _optimized suffix if this IS the optimized run\n",
    "saved_path = fold_models[-1].save_model(model_save_path)\n",
    "print(f\"Last fold TabNet model saved to path: {saved_path}\")\n",
    "\n",
    "# (Optional: Save the list of all fold models if needed for advanced ensembling/analysis)\n",
    "# with open(os.path.join(MODEL_OUTPUT_PATH, 'tabnet_fold_models.pkl'), 'wb') as f:\n",
    "#     pickle.dump(fold_models, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
